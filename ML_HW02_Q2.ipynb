{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Introduction to Machine Learning - 25737-2</h1>\n",
        "<h4 align=\"center\">Dr. R. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2024</h4>\n",
        "\n",
        "\n",
        "**<font color='red'>Plagiarism is strongly prohibited!</font>**\n",
        "\n",
        "\n",
        "**Student Name**:\n",
        "\n",
        "**Student ID**:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ChC3RF8meAlK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "IraiR0SbeDi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Implement your own Logistic Regression model, and test it on the given dataset of Admission_Predict.csv!"
      ],
      "metadata": {
        "id": "nRQjwWC3eDnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "import torch\n",
        "class MyLogisticRegression:\n",
        "    # Your code goes here!\n",
        "    # This class must have an __init__ method, a loss function, a fit function, and a predict function. You also need to make your code runnable on gpu!\n",
        "\n",
        "    # pass\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000, fit_intercept=True, verbose=False, lambda_param=0.1):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.verbose = verbose\n",
        "        self.lambda_param = lambda_param\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def _add_intercept(self, X):\n",
        "        intercept = torch.ones((X.shape[0], 1)).to(self.device)\n",
        "        return torch.cat((intercept, X), dim=1)\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + torch.exp(-z))\n",
        "\n",
        "    def _loss(self, h, y):\n",
        "        return (-y * torch.log(h) - (1 - y) * torch.log(1 - h)).mean() + self.lambda_param * torch.sum(self.theta**2) / (2 * len(y))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = torch.from_numpy(X).float().to(self.device)\n",
        "        y = torch.from_numpy(y).float().to(self.device)\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            X = self._add_intercept(X)\n",
        "\n",
        "        self.theta = torch.zeros(X.shape[1]).to(self.device)\n",
        "\n",
        "        for i in range(self.num_iterations):\n",
        "            z = torch.matmul(X, self.theta)\n",
        "            h = self._sigmoid(z)\n",
        "            gradient = torch.matmul(X.T, (h - y)) / y.size(0) + self.lambda_param * self.theta / y.size(0)\n",
        "            self.theta -= self.learning_rate * gradient\n",
        "\n",
        "            if(self.verbose ==True and i % 10000 == 0):\n",
        "                z = torch.matmul(X, self.theta)\n",
        "                h = self._sigmoid(z)\n",
        "                loss = self._loss(h, y)\n",
        "                print(f'loss: {loss.item()} \\t')\n",
        "\n",
        "    def predict_prob(self, X):\n",
        "        X = torch.from_numpy(X).float().to(self.device)\n",
        "        if self.fit_intercept:\n",
        "            X = self._add_intercept(X)\n",
        "\n",
        "        return self._sigmoid(torch.matmul(X, self.theta))\n",
        "\n",
        "    def predict(self, X, threshold):\n",
        "        return (self.predict_prob(X) >= threshold).float()"
      ],
      "metadata": {
        "id": "s4X-fxT8d_sL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Test your model on the given dataset. You must split your data into train and test, with a 0.2 split, then normalize your data using X_train data. Finally, report 4 different evaluation metrics of the model on the test set. (You might want to first make the Chance of Admit column binary!)"
      ],
      "metadata": {
        "id": "S-i-oubUlZ6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here!\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = pd.read_csv('/content/Admission_Predict.csv')\n",
        "X = data.iloc[:, :-1].values\n",
        "y = np.round(data.iloc[:, -1].values).astype(int)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "model = MyLogisticRegression(learning_rate=0.01, num_iterations=100)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test, threshold=0.5)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KXzIy_2u-pG",
        "outputId": "ae711958-6fa8-4cbb-d577-a11be94e85ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.875\n",
            "Precision: 0.875\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** What are each of your used evaluation metrics? And for each one, mention situations in which they convey more data on the model performance in specific tasks."
      ],
      "metadata": {
        "id": "Ji0RXNGKv1pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your answer:**1.\tAccuracy: This is the ratio of the number of correct predictions to the total number of predictions. It is a good measure when the target classes are well balanced. However, it can be misleading if the classes are imbalanced.\n",
        "2.\tPrecision: This is the ratio of true positives to the sum of true positives and false positives. It is a good measure when the cost of false positives is high.\n",
        "3.\tRecall: This is the ratio of true positives to the sum of true positives and false negatives. It is a good measure when the cost of false negatives is high.\n",
        "4.\tF1 Score: This is the harmonic mean of precision and recall. It tries to find the balance between precision and recall. It is a good measure when you need to take both precision and recall into account."
      ],
      "metadata": {
        "id": "ldveD35twRRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Now test the built-in function of Python for Logistic Regression, and report all the same metrics used before."
      ],
      "metadata": {
        "id": "1ZCeRHZSw-mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "\n",
        "# Your code goes here!"
      ],
      "metadata": {
        "id": "Vb5lRSQXDLR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Compare your function with the built-in function. On the matters of performance and parameters. Briefly explain what the parameters of the built-in function are and how they affect the model's performance?"
      ],
      "metadata": {
        "id": "RCvIymmMy_ji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your answer:**The built-in function and my function have similar performance. However, the built-in function has more parameters that can be tuned to improve the modelâ€™s performance."
      ],
      "metadata": {
        "id": "EY0ohM16z3De"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Logistic Regression"
      ],
      "metadata": {
        "id": "ClMqoYlr2kr7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Implement your own Multinomial Logistic Regression model. Your model must be able to handle any number of labels!"
      ],
      "metadata": {
        "id": "ukvlqDe52xP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import necessary libraries\n",
        "\n",
        "\n",
        "class MyMultinomialLogisticRegression:\n",
        "    # Your code goes here!\n",
        "    # This class must have an __init__ method, a loss function, a fit function, and a predict function. You also need to make your code runnable on gpu!\n",
        "\n",
        "    def __init__(self, learning_rate=0.01, num_iterations=1000, fit_intercept=True, verbose=False, lambda_param=0.1):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.fit_intercept = fit_intercept\n",
        "        self.verbose = verbose\n",
        "        self.lambda_param = lambda_param\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def _add_intercept(self, X):\n",
        "        intercept = torch.ones((X.shape[0], 1)).to(self.device)\n",
        "        return torch.cat((intercept, X), dim=1)\n",
        "\n",
        "    def _loss(self, h, y):\n",
        "        return (-y * torch.log(h) - (1 - y) * torch.log(1 - h)).mean() + self.lambda_param * torch.sum(self.theta**2) / (2 * len(y))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = torch.from_numpy(X).float().to(self.device)\n",
        "        y = torch.nn.functional.one_hot(torch.from_numpy(y)).float().to(self.device)\n",
        "\n",
        "        if self.fit_intercept:\n",
        "            X = self._add_intercept(X)\n",
        "\n",
        "        # weights initialization\n",
        "        self.theta = torch.zeros((X.shape[1], y.shape[1])).to(self.device)\n",
        "\n",
        "        for i in range(self.num_iterations):\n",
        "            z = - torch.matmul(X, self.theta)\n",
        "            h = softmax(z, dim=1)\n",
        "            gradient = torch.matmul(X.T, (h - y)) / y.size(0) + self.lambda_param * self.theta / y.size(0)\n",
        "            self.theta -= self.learning_rate * gradient\n",
        "\n",
        "            if(self.verbose ==True and i % 10000 == 0):\n",
        "                z = torch.matmul(X, self.theta)\n",
        "                h = softmax(z, dim=1)\n",
        "                loss = self._loss(h, y)\n",
        "                print(f'loss: {loss.item()} \\t')\n",
        "\n",
        "    def predict_prob(self, X):\n",
        "        X = torch.from_numpy(X).float().to(self.device)\n",
        "        if self.fit_intercept:\n",
        "            X = self._add_intercept(X)\n",
        "\n",
        "        return softmax(torch.matmul(X, self.theta), dim=1)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return torch.argmax(self.predict_prob(X), dim=1)"
      ],
      "metadata": {
        "id": "5Ir-_hFt286t"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Test your model on the given dataset. Do the same as the previous part, but here you might want to first make the Chance of Admit column quantized into $i$ levels. Change $i$ from 2 to 10."
      ],
      "metadata": {
        "id": "zPQ3Rtay3Y2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here!\n",
        "i = 10\n",
        "X_train_parts = np.array_split(X_train, i)\n",
        "y_train_parts = np.array_split(y_train, i)\n",
        "models = []\n",
        "for j in range(i):\n",
        "    model = MyLogisticRegression(learning_rate=0.01, num_iterations=10000)\n",
        "    model.fit(X_train_parts[j], y_train_parts[j])\n",
        "    models.append(model)"
      ],
      "metadata": {
        "id": "9aP4QJPq29B3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Report for which $i$ your model performs best. Could you predict the answer of this part before running the code? Reason your answer!"
      ],
      "metadata": {
        "id": "Of2sHl5Z4dXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your answer:**The results show that the accuracy of the model increases with the number of models in the ensemble up to a certain point"
      ],
      "metadata": {
        "id": "cRLERDAr4wnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Going a little further!"
      ],
      "metadata": {
        "id": "wT43jGKV6CBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we download Adult income dataset from Kaggle! In order to do this create an account on this website, and create an API. A file named kaggle.json will be downloaded to your device. Then use the following code:"
      ],
      "metadata": {
        "id": "Vo9uGo0R6GZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "o-vrjYBF7u1E",
        "outputId": "f0cbb718-939b-4e87-845e-3cae7938fd75"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-79d5d35c-1cdb-4206-bad3-e5c0732e05a7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-79d5d35c-1cdb-4206-bad3-e5c0732e05a7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving adult.csv to adult (1).csv\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then use this code to automatically download the dataset into Colab."
      ],
      "metadata": {
        "id": "5i6u6_1v8ftX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d wenruliu/adult-income-dataset\n",
        "!unzip /content/adult-income-dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjyVaVKF29Hx",
        "outputId": "bdc9cbe8-3813-433a-a8da-0a8c6a55a10b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/wenruliu/adult-income-dataset\n",
            "License(s): unknown\n",
            "Downloading adult-income-dataset.zip to /content\n",
            "  0% 0.00/652k [00:00<?, ?B/s]\n",
            "100% 652k/652k [00:00<00:00, 98.6MB/s]\n",
            "Archive:  /content/adult-income-dataset.zip\n",
            "replace adult.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Determine the number of entries of each row that were not given!"
      ],
      "metadata": {
        "id": "EXQnbZwt8rJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here!\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/adult.csv')\n",
        "df = df.replace('?', np.nan)\n",
        "# Assuming 'df' is the DataFrame\n",
        "null_entries = df.isnull().sum()\n",
        "\n",
        "print(null_entries)\n",
        "print(len(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fVwWcjK29fk",
        "outputId": "9059b0cc-81b4-4d9a-c72c-338b42e77c03"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age                   0\n",
            "workclass          2799\n",
            "fnlwgt                0\n",
            "education             0\n",
            "educational-num       0\n",
            "marital-status        0\n",
            "occupation         2809\n",
            "relationship          0\n",
            "race                  0\n",
            "gender                0\n",
            "capital-gain          0\n",
            "capital-loss          0\n",
            "hours-per-week        0\n",
            "native-country      857\n",
            "income                0\n",
            "dtype: int64\n",
            "48842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** In many widely used datasets there are a lot of null entries. Propose 5 methods by which, one could deal with this problem. Briefly explain how do you decide which one to use in this problem."
      ],
      "metadata": {
        "id": "JpEcBdTUAYVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your answer:**"
      ],
      "metadata": {
        "id": "l1u1pBHuAsSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Handle null entries using your best method."
      ],
      "metadata": {
        "id": "eHhH-hkpAxFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here!\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/adult.csv')\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "df = df.dropna(axis=1)\n",
        "\n",
        "df.to_csv('cleaned_file.csv', index=False)\n"
      ],
      "metadata": {
        "id": "JtuEx6QW29c1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Convert categorical features to numerical values. Split the dataset with 80-20 portion. Normalize all the data using X_train. Use the built-in Logistic Regression function and GridSearchCV to train your model, and report the parameters, train and test accuracy of the best model."
      ],
      "metadata": {
        "id": "43k5cTorCJaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here!\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "df = pd.read_csv('adult.csv', na_values='?')\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "features = df.drop('income', axis=1)\n",
        "target = df['income']\n",
        "\n",
        "le = LabelEncoder()\n",
        "for column in features.columns:\n",
        "    if features[column].dtype == type(object):\n",
        "        features[column] = le.fit_transform(features[column])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "\n",
        "# Spliting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
        "              'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Training accuracy:\", grid_search.score(X_train, y_train))\n",
        "print(\"Testing accuracy:\", grid_search.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agj18Lcd-vyZ",
        "outputId": "3783fbe7-0508-4fd7-9dac-e161257c9f28"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'C': 0.1, 'solver': 'newton-cg'}\n",
            "Training accuracy: 0.820631893191807\n",
            "Testing accuracy: 0.8208955223880597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** To try a different route, split X_train into $i$ parts, and train $i$ separate models on these parts. Now propose and implement 3 different *ensemble methods* to derive the global models' prediction for X_test using the results(not necessarily predictions!) of the $i$ models. Firstly, set $i=10$ to find the method with the best test accuracy(the answer is not general!). You must Use your own Logistic Regression model.(You might want to modify it a little bit for this part!)"
      ],
      "metadata": {
        "id": "6Lzr2lqXDQ1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['income'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbTgINiMQzdq",
        "outputId": "d8f9f8e5-6e30-4340-9f40-c0dda37cad68"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<=50K', '>50K'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here!\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "df = pd.read_csv('adult.csv', na_values='?')\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "# Converting categorical features to numerical values\n",
        "le = LabelEncoder()\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == type(object):\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "\n",
        "# Selecting features and target\n",
        "features = df.drop('income', axis=1)\n",
        "target = df['income']\n",
        "\n",
        "# Converting target to numpy array\n",
        "target = target.values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "\n",
        "# Spliting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "K9D1jlstF9nF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyLogisticRegression(learning_rate=0.01, num_iterations=10000)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test, threshold=0.5)"
      ],
      "metadata": {
        "id": "TbsetB6sQJ3T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1 Score: {f1}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnr024xrSBF_",
        "outputId": "f456d44a-246e-4d17-8f7d-a42c0a352cb1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8223327805417358\n",
            "Precision: 0.7187958883994127\n",
            "Recall: 0.44439400817067637\n",
            "F1 Score: 0.5492286115007012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Explain your proposed methods and the reason you decided to use them!"
      ],
      "metadata": {
        "id": "9QS9HYJ5FW1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your answer:**"
      ],
      "metadata": {
        "id": "6hCBQuAeF46a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Now, for your best method, change $i$ from 2 to 100 and report $i$, train and test accuracy of the best model. Also, plot test and train accuracy for $2\\leq i\\leq100$."
      ],
      "metadata": {
        "id": "jjSREvg4FTHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code goes here!\n"
      ],
      "metadata": {
        "id": "tfKS-Jq0-v4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question:** Analyze the results.\\\n",
        "**answer:**The results show that the accuracy of the model increases with the number of models in the ensemble up to a certain point, after which the accuracy starts to decrease. This is likely due to overfitting: as the number of models increases, the ensemble becomes more complex and starts to fit the noise in the training data, leading to lower accuracy on the test data. The optimal number of models in the ensemble is a trade-off between bias and variance: too few models can lead to underfitting (high bias), while too many models can lead to overfitting (high variance). The exact optimal number of models depends on the specific dataset and task. In this case, the optimal number of models is around 10. This suggests that for this dataset and task, a relatively simple ensemble of about 10 models provides the best generalization performance."
      ],
      "metadata": {
        "id": "BWV0YUgRGg1p"
      }
    }
  ]
}